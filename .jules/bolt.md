## 2025-05-15 - [get_dataset Optimization] **Learning:** Identified significant overhead in `get_dataset` due to iterative type resolution and coercion using `dplyr` pipelines. Using base R's `lapply`, `vapply`, `split`, and `do.call` for metadata handling and batch coercion provided a 25x speedup in coercion and a 6x speedup in type resolution. **Action:** Prefer base R primitives over `dplyr`/`purrr` when processing lists of many data frames or when comparing column types across resources.

## 2025-05-15 - [add_context Optimization] **Learning:** `dplyr::mutate(..., .before = everything())` is significantly slower than `tibble::tibble()` followed by `dplyr::bind_cols()` for prepending constant metadata columns. **Action:** Use `bind_cols` for prepending context/metadata, ensuring existing columns are manually removed first to maintain `mutate` overwrite behavior.

## 2025-05-15 - [httr2 Migration & Error Handling] **Learning:** `httr2::req_perform()` throws errors for 4xx/5xx responses by default, which can bypass existing custom error parsing logic. Additionally, `httr2` might return JSON error bodies with a `text/html` content type. **Action:** Use `httr2::req_error(is_error = function(resp) FALSE)` to maintain compatibility with legacy error checking, and use `tryCatch` with `xml2::read_html` as a fallback when parsing JSON fails on HTML-labeled responses.
